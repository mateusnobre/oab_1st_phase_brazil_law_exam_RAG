{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0_TOlWhBIPLk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_TOlWhBIPLk",
    "outputId": "b9d8dbd8-94ac-462f-aeb2-f278a074ead9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install llama_index qdrant_client langchain pymupdf replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc4edb-5dd6-4918-bafb-00223a3f4214",
   "metadata": {
    "id": "9fdc4edb-5dd6-4918-bafb-00223a3f4214",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from qdrant_client import QdrantClient\n",
    "import fitz\n",
    "import os\n",
    "from llama_index import Document\n",
    "from tqdm import tqdm\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index import SimpleDirectoryReader, VectorStoreIndex, ServiceContext, StorageContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.embeddings import LangchainEmbedding\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index import load_index_from_storage\n",
    "from llama_index.prompts import PromptTemplate\n",
    "import random\n",
    "import time\n",
    "\n",
    "OPENAI_API_KEY=\"OPENAI_API_KEY\"\n",
    "REPLICATE_API_TOKEN=\"REPLICATE_API_TOKEN\"\n",
    "\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.llms.palm import PaLM\n",
    "from llama_index.llms import Replicate\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n",
    "\n",
    "TEMPERATURE = 0.2\n",
    "MAX_TOKENS = 50\n",
    "MAX_CONTEXT_WINDOW = 4096\n",
    "\n",
    "llama2_13b_llm = Replicate(\n",
    "    model=\"meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d\",\n",
    "    context_window=MAX_CONTEXT_WINDOW,\n",
    "    temperature=TEMPERATURE\n",
    "\n",
    ")\n",
    "\n",
    "llama2_70b_llm = Replicate(\n",
    "    model=\"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    context_window=MAX_CONTEXT_WINDOW,\n",
    "    temperature=TEMPERATURE\n",
    ")\n",
    "\n",
    "gpt35_llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=TEMPERATURE\n",
    ")\n",
    "gpt4_llm = OpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=TEMPERATURE\n",
    ")\n",
    "\n",
    "llms_list = [\n",
    "    {\"model_name\" : \"GPT 3.5\", \"license\": \"commercial\",\"model_object\": gpt35_llm},\n",
    "    {\"model_name\" : \"GPT 4\", \"license\": \"commercial\",\"model_object\": gpt4_llm},\n",
    "    {\"model_name\" : \"Llama2 13B\", \"license\": \"open-source\",\"model_object\": llama2_13b_llm},\n",
    "    {\"model_name\" : \"Llama2 70B\", \"license\": \"open-source\",\"model_object\": llama2_70b_llm},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uFDUyruGIcXt",
   "metadata": {
    "id": "uFDUyruGIcXt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_models = [\n",
    "    {\"model_name\" : \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", \"license\": \"open-source\"},\n",
    "    {\"model_name\" : \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", \"license\": \"open-source\"},\n",
    "    {\"model_name\" : \"text-embeddings-ada-002\", \"license\": \"commercial\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07835fd8-0e80-4bc2-80d5-abb11188090e",
   "metadata": {
    "id": "07835fd8-0e80-4bc2-80d5-abb11188090e",
    "tags": []
   },
   "source": [
    "# Loading Vade Mecum to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305ddf1-abb1-4708-8e33-1d25192437c6",
   "metadata": {
    "id": "9305ddf1-abb1-4708-8e33-1d25192437c6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'Vade_mecum_2023.pdf.json') as f:\n",
    "    vade_mecum_2023 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P5SGdCDuHsVK",
   "metadata": {
    "id": "P5SGdCDuHsVK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6bd17e-fab5-4307-9b6d-fdbfe3a51536",
   "metadata": {
    "id": "5e6bd17e-fab5-4307-9b6d-fdbfe3a51536",
    "tags": []
   },
   "outputs": [],
   "source": [
    "QDRANT_CLIENT_TOKEN = \"QDRANT_CLIENT_TOKEN\"\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://RAANDOM URL.us-east-1-0.aws.cloud.qdrant.io:6333\",\n",
    "    api_key=QDRANT_CLIENT_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76b88c-f071-4172-b0f5-1d1fcb763d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vade_mecum_2023['17'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e16a8-7e54-4dae-bcb9-658a1253e417",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a68e16a8-7e54-4dae-bcb9-658a1253e417",
    "outputId": "4baf574c-4847-4328-f70f-b6e7dfdb39f3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents_list = []\n",
    "for page_number, page_content in vade_mecum_2023.items():\n",
    "    documents_list.append(\n",
    "        Document(\n",
    "            text=page_content[\"text\"],\n",
    "            metadata={\n",
    "                'page_number': int(page_number),\n",
    "                'chapter_title': page_content['chapter_title']\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bace788-21f4-4f0b-bba2-724ccb455c93",
   "metadata": {
    "id": "1bace788-21f4-4f0b-bba2-724ccb455c93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_embedding_model(embedding_model_name):\n",
    "    if embedding_model_name == \"text-embeddings-ada-002\":\n",
    "        embed_model = open_ai_embeddings = OpenAIEmbedding(embed_batch_size=50,OPENAI_API_KEY=OPENAI_API_KEY)\n",
    "    else:\n",
    "        model_kwargs = {\"device\": \"cpu\"}\n",
    "        encode_kwargs = {\"normalize_embeddings\": False}\n",
    "        embed_model = LangchainEmbedding(\n",
    "            HuggingFaceEmbeddings(\n",
    "                model_name=embedding_model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    "            )\n",
    "        )\n",
    "    return embed_model\n",
    "\n",
    "def generate_index(documents, embedding_model_name):\n",
    "    node_parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=64)\n",
    "    embed_model = get_embedding_model(embedding_model_name)\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        node_parser=node_parser,\n",
    "        embed_model=embed_model\n",
    "\n",
    "    )\n",
    "    qdrant_vector_store = QdrantVectorStore(\n",
    "            client=qdrant_client, collection_name=\"rag_\"+embedding_model_name.replace(\"-\", \"_\").replace(\"/\", \"_\")\n",
    "        )\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "                        vector_store=qdrant_vector_store,\n",
    "                    )\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, service_context=service_context, storage_context=storage_context, show_progress=True\n",
    "    )\n",
    "\n",
    "    index.storage_context.persist(\n",
    "        persist_dir=f\"indexes_metadata/\" + \"rag_\"+ embedding_model_name,\n",
    "    )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33cd89a-1c1b-4c4b-be39-7d7753d6b9e5",
   "metadata": {
    "id": "e33cd89a-1c1b-4c4b-be39-7d7753d6b9e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for embedding_model in embeddings_models:\n",
    "    print(embedding_model[\"model_name\"])\n",
    "    generate_index(documents_list, embedding_model[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b64a91-54dc-494f-b6e3-e399dacfa8f4",
   "metadata": {
    "id": "e5b64a91-54dc-494f-b6e3-e399dacfa8f4",
    "tags": []
   },
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40683a-64cc-4288-962b-6d27496289e2",
   "metadata": {
    "id": "3a40683a-64cc-4288-962b-6d27496289e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'1A FASE OAB/37º EXAME DE ORDEM UNIFICADO TIPO 1 - BRANCA.pdf.json') as f:\n",
    "    oab_37 = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ad264-3be3-457b-9c9a-edb26443de5a",
   "metadata": {
    "id": "4d4ad264-3be3-457b-9c9a-edb26443de5a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_text(oab_dict):\n",
    "    LEFT_STR = \"\"\n",
    "    RIGHT_STR = \"\"\n",
    "\n",
    "    for item in oab_37:\n",
    "        if item[\"metadata\"][\"page_number\"] >= 3 and item[\"metadata\"][\"page_number\"] <= 22:\n",
    "            is_right_side = False\n",
    "            for idx in range(4):\n",
    "                if item[\"coordinates\"][idx][0] > 300:\n",
    "                    is_right_side = True\n",
    "            if is_right_side:\n",
    "                # print(item[\"coordinates\"], item[\"text\"])\n",
    "                RIGHT_STR += item[\"text\"]\n",
    "                RIGHT_STR += \"\\n\"\n",
    "            else:\n",
    "                # print(item[\"coordinates\"], item[\"text\"])\n",
    "                LEFT_STR += item[\"text\"]\n",
    "                LEFT_STR += \"\\n\"\n",
    "    return LEFT_STR, RIGHT_STR\n",
    "\n",
    "def extract_strings(text):\n",
    "    def extract_between_markers(marker1, marker2, input_text):\n",
    "        pattern = re.compile(f'{re.escape(marker1)}(.*?)\\s{re.escape(marker2)}', re.DOTALL)\n",
    "        matches = pattern.findall(input_text)\n",
    "        return [match.strip() for match in matches][0]\n",
    "\n",
    "    a_to_b = extract_between_markers('A)', 'B)', text)\n",
    "    b_to_c = extract_between_markers('B)', 'C)', text)\n",
    "    c_to_d = extract_between_markers('C)', 'D)', text)\n",
    "\n",
    "    pattern_d = re.compile(r'D\\)(.*)', re.DOTALL)\n",
    "    match_d = pattern_d.search(text)\n",
    "    after_d = match_d.group(1).strip() if match_d else \"\"\n",
    "\n",
    "    return a_to_b, b_to_c, c_to_d, after_d\n",
    "\n",
    "def get_questions_from_text(left_side_str, right_side_str):\n",
    "    # Define a regular expression pattern to split the text into individual questions\n",
    "    pattern = r'\\n?(\\d+)\\n?(.*?)(?=\\n\\d+|$)'\n",
    "    questions = {}\n",
    "    # Use re.findall to find all matches in the text\n",
    "    left_side_questions = re.findall(pattern, left_side_str.replace(\"XXXVII EXAME DE ORDEM UNIFICADO – TIPO 1 – BRANCA PROVA APLICADA EM 26/2/2023\", \"\"), re.DOTALL)\n",
    "    right_side_questions = re.findall(pattern, right_side_str.replace(\"XXXVII EXAME DE ORDEM UNIFICADO – TIPO 1 – BRANCA PROVA APLICADA EM 26/2/2023\", \"\"), re.DOTALL)\n",
    "\n",
    "    # Iterate through the questions and print them\n",
    "    for question in left_side_questions:\n",
    "        number, text = question\n",
    "        question =  text.split(\"A)\")[0]\n",
    "        alternatives  = extract_strings(text)\n",
    "        a_answer, b_answer, c_answer, d_answer = alternatives[0],alternatives[1],alternatives[2],alternatives[3]\n",
    "        questions[int(number)] = {\n",
    "        \"question_text\" : question,\n",
    "         \"a_answer\" : a_answer,\n",
    "         \"b_answer\" : b_answer,\n",
    "         \"c_answer\" : c_answer,\n",
    "         \"d_answer\" : d_answer,\n",
    "        }\n",
    "\n",
    "    for question in right_side_questions:\n",
    "        number, text = question\n",
    "        question =  text.split(\"A)\")[0]\n",
    "        if question != \"\":\n",
    "            alternatives_text = text.split(f\"{question}\")[1]\n",
    "            alternatives = extract_strings(alternatives_text)\n",
    "            a_answer, b_answer, c_answer, d_answer = alternatives[0],alternatives[1],alternatives[2],alternatives[3]\n",
    "            questions[int(number)] = {\n",
    "            \"question_text\" : question,\n",
    "             \"a_answer\" : a_answer,\n",
    "             \"b_answer\" : b_answer,\n",
    "             \"c_answer\" : c_answer,\n",
    "             \"d_answer\" : d_answer,\n",
    "            }\n",
    "    return questions\n",
    "def get_oab_df(oab_dict):\n",
    "    left_str, right_str = extract_text(oab_dict)\n",
    "    questions = get_questions_from_text(left_str, right_str)\n",
    "    oab_df = pd.DataFrame(questions).T.reset_index().rename(columns={\"index\":\"question_number\"}).sort_values(\"question_number\").reset_index(drop=True)\n",
    "    return oab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c0ab7-36cf-4a23-a1ca-3defa5ea92ca",
   "metadata": {
    "id": "044c0ab7-36cf-4a23-a1ca-3defa5ea92ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "oab_37_df = get_oab_df(oab_37)\n",
    "oab_37_df.to_csv(f\"oab_37_df.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9e5f7-4165-46bf-afa9-ba2d6970cda3",
   "metadata": {
    "id": "43d9e5f7-4165-46bf-afa9-ba2d6970cda3"
   },
   "outputs": [],
   "source": [
    "oab_37_df = pd.read_csv(\"oab_37_df.csv\", sep =\";\")\n",
    "with open(f'1A FASE OAB/XXXVII EXAME UNIFICADO – GABARITOS.json') as f:\n",
    "    answers_oab_37_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e67cc4-28c5-4717-9bb6-7e0f2bceea5c",
   "metadata": {
    "id": "94e67cc4-28c5-4717-9bb6-7e0f2bceea5c"
   },
   "outputs": [],
   "source": [
    "oab_37_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334875b4-83a8-4cff-bf2e-50d5e2c29cd8",
   "metadata": {
    "id": "334875b4-83a8-4cff-bf2e-50d5e2c29cd8",
    "tags": []
   },
   "source": [
    "# Evaluating LLM Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec42c4-26fd-4604-b608-4c833ca06f62",
   "metadata": {
    "id": "edec42c4-26fd-4604-b608-4c833ca06f62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_index_from_context(embedding_model_name):\n",
    "\n",
    "    node_parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=64)\n",
    "    embed_model = get_embedding_model(embedding_model_name)\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        node_parser=node_parser,\n",
    "        embed_model=embed_model\n",
    "    )\n",
    "    qdrant_vector_store = QdrantVectorStore(\n",
    "            client=qdrant_client, collection_name=\"rag_\"+embedding_model_name.replace(\"-\", \"_\").replace(\"/\", \"_\")\n",
    "        )\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "                        vector_store=qdrant_vector_store,\n",
    "                        persist_dir=f\"indexes_metadata/rag_\"+embedding_model_name\n",
    "                    )\n",
    "\n",
    "    index = load_index_from_storage(\n",
    "        service_context=service_context, storage_context=storage_context\n",
    "    )\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f95732-aadb-4b11-88b4-9796eae09b9b",
   "metadata": {
    "id": "66f95732-aadb-4b11-88b4-9796eae09b9b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_results(questions, answers, llm, retriever, n_chunks_to_use_rag=5,use_rag=True):\n",
    "\n",
    "    qa_prompt_tmpl_str = \"\"\"\\\n",
    "    You are an experienced brazilain lawyer and your job is to use the following brazilian laws and your current knowledge to answer multiple choice questions\n",
    "    ---------------------\n",
    "    BRAZILIAN LAWS:\n",
    "    {vade_mecum_laws_str}\n",
    "    ---------------------\n",
    "    Given the brazilian laws mentioned above and your current knowledge, answer the multiple choice question below\n",
    "    Question:\n",
    "    {query_str}\n",
    "\n",
    "\n",
    "    ONLY ANSWER THE CORRECT ALTERNATIVE BETWEEN A, B, C or D\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
    "    response_with_answers_dict = {}\n",
    "    for question_number in range(1,81):\n",
    "        response_with_answers_dict[str(question_number)] = {\n",
    "            \"llm_response_text\" : \"\",\n",
    "            \"answer\": \"\",\n",
    "        }\n",
    "    with tqdm(total=len(questions)) as pbar:\n",
    "      for _, question in questions.iterrows():\n",
    "        query_str = f\"\"\"\n",
    "        Question: {question[\"question_text\"]}\n",
    "\n",
    "        Alternatives:\n",
    "        - A) {question[\"a_answer\"]}\n",
    "        - B) {question[\"b_answer\"]}\n",
    "        - C) {question[\"c_answer\"]}\n",
    "        - D) {question[\"d_answer\"]}\n",
    "        \"\"\"\n",
    "        if retriever is not None:\n",
    "          vade_mecum_laws_nodes = retriever.retrieve(query_str)\n",
    "          vade_mecum_laws_str = \"\"\n",
    "          for node in vade_mecum_laws_nodes:\n",
    "            vade_mecum_laws_str += node.text\n",
    "            vade_mecum_laws_str += \"\\n\"\n",
    "        else:\n",
    "          vade_mecum_laws_str = \"NO CONTEXT PROVIDED\"\n",
    "        fmt_prompt = prompt_tmpl.format(\n",
    "            vade_mecum_laws_str=vade_mecum_laws_str,\n",
    "            query_str=query_str\n",
    "        )\n",
    "        n_tries = 0\n",
    "        max_tries = 5\n",
    "\n",
    "        while n_tries < max_tries and response_with_answers_dict[str(question[\"question_number\"])][\"llm_response_text\"] == \"\":\n",
    "            try:\n",
    "                n_tries += 1\n",
    "                result = llm[\"model_object\"].complete(fmt_prompt)\n",
    "                # Do something with the result if needed\n",
    "                response_with_answers_dict[str(question[\"question_number\"])][\"llm_response_text\"] = result.text\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                time.sleep(5)  # Wait for 5 seconds before the next try\n",
    "        if response_with_answers_dict[str(question[\"question_number\"])][\"llm_response_text\"] == \"\":\n",
    "          response_with_answers_dict[str(question[\"question_number\"])][\"llm_response_text\"] = \"FAIL\"\n",
    "        pbar.update(1)\n",
    "\n",
    "    correct_answers = 0\n",
    "\n",
    "    def get_answer_from_llm_response(llm_response_text):\n",
    "      pattern = re.compile(r'\\b([A-D])\\)')\n",
    "      if llm_response_text == \"\":\n",
    "        return \"FAIL\"\n",
    "      else:\n",
    "        match = pattern.search(llm_response_text)\n",
    "        if match:\n",
    "            # print(f\"{match.group(0).replace(')','')}\")\n",
    "            return match.group(0).replace(')','')\n",
    "        else:\n",
    "          return \"FAIL\"\n",
    "\n",
    "    for question_number  in range(1,81):\n",
    "      expected_answer = answers[str(question_number)]\n",
    "      llm_answer = get_answer_from_llm_response(response_with_answers_dict[str(question_number)][\"llm_response_text\"])\n",
    "      response_with_answers_dict[str(question_number)][\"answer\"]= llm_answer\n",
    "      if expected_answer == \"*\":\n",
    "        correct_answers +=1\n",
    "      if expected_answer == llm_answer:\n",
    "        correct_answers +=1\n",
    "\n",
    "    score = (100 * correct_answers/80)\n",
    "    return score, response_with_answers_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621a005-7c66-42a7-8a9a-f6f0db68d592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-eknm0s2_-sr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "id": "-eknm0s2_-sr",
    "outputId": "ea2fad7d-e2b0-4fe8-adf2-25c8fcef2b3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_relevant_chunks_to_retrieve = [5]\n",
    "results_records = []\n",
    "results_columns = [\n",
    "    \"oab_edition_number\",\n",
    "    \"llm_name\",\n",
    "    \"llm_license\",\n",
    "    \"embed_model_name\",\n",
    "    \"embed_model_license\",\n",
    "    \"n_chunks_retrieved_per_question\",\n",
    "    \"score\",\n",
    "    \"answers_dict\",\n",
    "]\n",
    "for oab_df, answers_df,oab_edition in zip([oab_37_df], [answers_oab_37_dict],[\"37\"]):\n",
    "  for llm in llms_list:\n",
    "    llm_baseline_score, llm_baseline_response_with_answers_dict = get_results(oab_df, answers_df, llm, None, n_chunks_to_use_rag=None,use_rag=False)\n",
    "    results_records.append([\n",
    "        oab_edition,\n",
    "        llm[\"model_name\"],\n",
    "        llm[\"license\"],\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        llm_baseline_score,\n",
    "        llm_baseline_response_with_answers_dict\n",
    "    ])\n",
    "    print(\n",
    "      oab_edition,\n",
    "      llm[\"model_name\"],\n",
    "      llm[\"license\"],\n",
    "      \"NONE\",\n",
    "      \"NONE\",\n",
    "      0,\n",
    "      llm_baseline_score\n",
    "    )\n",
    "    for embed_model in embeddings_models:\n",
    "      index = load_index_from_context(embed_model[\"model_name\"])\n",
    "\n",
    "      for top_k in number_of_relevant_chunks_to_retrieve:\n",
    "          retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "          score, response_with_answers_dict = get_results(oab_df, answers_df, llm, retriever, n_chunks_to_use_rag=top_k,use_rag=True)\n",
    "          print(\n",
    "              oab_edition,\n",
    "              llm[\"model_name\"],\n",
    "              llm[\"license\"],\n",
    "              embed_model[\"model_name\"],\n",
    "              embed_model[\"license\"],\n",
    "              top_k,\n",
    "              score\n",
    "          )\n",
    "\n",
    "          results_records.append([\n",
    "              oab_edition,\n",
    "              llm[\"model_name\"],\n",
    "              llm[\"license\"],\n",
    "              embed_model[\"model_name\"],\n",
    "              embed_model[\"license\"],\n",
    "              top_k,\n",
    "              score,\n",
    "              response_with_answers_dict\n",
    "              ]\n",
    "results_df = pd.DataFrame(results_records,columns=results_columns)\n",
    "      display(results_df)\n",
    "              )\n",
    "\n",
    "          results_df = pd.DataFrame(results_records,columns=results_columns)\n",
    "          display(results_df)\n",
    "          results_df.to_csv(f\"partial_results.csv\", sep =\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ce7e9-7728-472a-bbce-e15b7025e5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TBuH_StQm5wP",
   "metadata": {
    "id": "TBuH_StQm5wP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa518f5-b4b7-4420-b902-8abfd94729fc",
   "metadata": {
    "id": "8fa518f5-b4b7-4420-b902-8abfd94729fc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "07835fd8-0e80-4bc2-80d5-abb11188090e",
    "e5b64a91-54dc-494f-b6e3-e399dacfa8f4",
    "811d7ea8-1fcf-4f4f-be32-726c3119b26f"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
